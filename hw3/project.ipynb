{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def crawler():\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "    url = 'https://gg12.ru/category/stati/page/%s'\n",
    "    craw_list = []\n",
    "    for i in range(1, 29):\n",
    "        req = urllib.request.Request(url % i, headers={'User-Agent':user_agent})\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            html = response.read().decode('utf-8')\n",
    "        artcls_lnks = re.findall('<article .+?href=\"[^\"]+\"', html, re.DOTALL)\n",
    "        for lnk in artcls_lnks:\n",
    "            link = re.search('href=\"([^\"]+)\"', lnk).group(1)\n",
    "            craw_list.append(link)\n",
    "    return craw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mystem(content, date, file_number):\n",
    "#    print('yes')\n",
    "#    os.system('cd /Users/new.aloha/Downloads/')\n",
    "#    os.system(\"% echo '\" + content + \"' | ./mystem - output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ready():\n",
    "    root = 'Газета Йошкар-Ола'\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "    tab = root + os.sep + 'meta.csv'\n",
    "    line = 'path\\tauthor\\theader\\tcreated\\t'\n",
    "    line += 'sphere\\ttopic\\tstyle\\taudience_age\\t'\n",
    "    line += 'audience_level\\taudience_size\\tsource\\t'\n",
    "    line += 'publication\\tpubl_year\\tmedium\\t'\n",
    "    line += 'country\\tregion\\tlanguage\\n'\n",
    "    if not os.path.exists(tab):\n",
    "        f = open(tab, 'w', encoding = 'utf-8')\n",
    "        f.write(line)\n",
    "        f.close()\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page(url, file_number, tab):\n",
    "    root = 'Газета Йошкар-Ола'\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        html = response.read().decode('UTF-8')\n",
    "    beginning = html.find('<div class=\"entry-content\">')\n",
    "    beginning = html.find('<p>', beginning)\n",
    "    end = html.find('<div class=\"post-views')\n",
    "    content = html[beginning:end]\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    content = soup.get_text()\n",
    "    for i in range(len(content)):\n",
    "        if content[i] == '.':\n",
    "            content = content[:i+1] + '\\n' + content[i+1:]\n",
    "            # каждое предложение на новой строчке\n",
    "    beginning = html.find('entry-date published updated')\n",
    "    beginning = html.find('>', beginning)+1\n",
    "    end = html.find('<', beginning)\n",
    "    date = html[beginning:end].split('.')\n",
    "    beginning = html.find('<title>') + len('<title>')\n",
    "    end = html.find(' | Газета Йошкар-Ола', beginning)\n",
    "    title = html[beginning:end]\n",
    "    if html.find('<meta name=\"author\" content=\"') != -1:\n",
    "        beginning = html.find('<meta name=\"author\" content=\"')+len('<meta name=\"author\" content=\"')\n",
    "        end = html.find('\"/>', beginning)\n",
    "        author = html[beginning:end]\n",
    "    else:\n",
    "        author = 'None'\n",
    "    pattern = '>([а-яА-Я ]*)[^а-яА-Я]*?>\\s*?<h1'\n",
    "    if re.search(pattern, html):\n",
    "        topic = re.search(pattern, html).group(1)\n",
    "    else:\n",
    "        topic = 'None'\n",
    "    directory = root + os.sep + 'plain' + os.sep \n",
    "    if len(date) != 3:\n",
    "        directory += 'None' + os.sep\n",
    "        date1 = 'None'\n",
    "        date2 = 'None'\n",
    "    else:\n",
    "        directory += date[2] + os.sep + date[1] + os.sep\n",
    "        date1 = '.'.join(date)\n",
    "        date2 = date[2]\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    f = open(directory + 'статья' + file_number + '.txt', 'w', encoding='utf-8')\n",
    "    f.write('@au ' + author + '\\n')\n",
    "    f.write('@ti ' + title + '\\n')\n",
    "    f.write('@da ' + date1 + '\\n')\n",
    "    f.write('@topic' + topic + '\\n')\n",
    "    f.write('@url' + url + '\\n')\n",
    "    f.write(content)\n",
    "    f.close()\n",
    "    with open(tab, 'a', encoding='utf-8') as fm:\n",
    "        row = '%s\\t%s\\t%s\\t%s\\tпублицистика\\t%s\\tнейтральный\\tн-возраст\\tн-уровень\\tгородская\\t%s\\tГазета Йошкар-Ола\\t%s\\tгазета\\tРоссия\\tМарий Эл\\tru\\n' % (directory + 'статья' + file_number + '.txt', author, title, date1, topic, url, date2)\n",
    "        fm.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "craw_list = crawler()\n",
    "tab = get_ready()\n",
    "for number, url in enumerate(craw_list):\n",
    "    page(url, str(number), tab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
